{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ABInBev Case - Interactive Queries\n",
                "\n",
                "Use this notebook to query the data processed by the pipeline. Tables are loaded as temporary views."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pyspark.sql import SparkSession\n",
                "\n",
                "# Configurar SparkSession com Delta Lake\n",
                "spark = (SparkSession.builder\n",
                "    .appName(\"ABInBev_Interactive_Query\")\n",
                "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\")\n",
                "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
                "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
                "    .getOrCreate())\n",
                "\n",
                "# Caminho base dos dados (assumindo execucao na raiz do projeto ou ajustando path)\n",
                "DATA_DIR = \"../data\" if os.path.exists(\"../data\") else \"data\"\n",
                "\n",
                "print(f\"Spark Version: {spark.version}\")\n",
                "print(f\"Data Directory: {DATA_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Tables\n",
                "Loading tables from Silver, Gold, and Consumption layers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Silver\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/silver/silver_sales_enriched\").createOrReplaceTempView(\"silver_sales\")\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/silver/silver_channel_features\").createOrReplaceTempView(\"silver_channels\")\n",
                "\n",
                "# Gold\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/gold/gold_sales_enriched\").createOrReplaceTempView(\"gold_sales\")\n",
                "\n",
                "# Consumption (Dimensions & Facts)\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/consumption/dim_date\").createOrReplaceTempView(\"dim_date\")\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/consumption/dim_product\").createOrReplaceTempView(\"dim_product\")\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/consumption/dim_region\").createOrReplaceTempView(\"dim_region\")\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/consumption/dim_channel\").createOrReplaceTempView(\"dim_channel\")\n",
                "spark.read.format(\"delta\").load(f\"{DATA_DIR}/consumption/fact_sales\").createOrReplaceTempView(\"fact_sales\")\n",
                "\n",
                "print(\"Tables loaded and registered as Temp Views!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Business Questions\n",
                "### 2.1 Top 3 Trade Groups by Region"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query_1 = \"\"\"\n",
                "SELECT \n",
                "    r.region_name,\n",
                "    c.trade_group_desc,\n",
                "    SUM(f.dollar_volume) as total_dollar_volume\n",
                "FROM fact_sales f\n",
                "JOIN dim_region r ON f.region_key = r.region_key\n",
                "JOIN dim_channel c ON f.channel_key = c.channel_key\n",
                "GROUP BY r.region_name, c.trade_group_desc\n",
                "ORDER BY r.region_name, total_dollar_volume DESC\n",
                "\"\"\"\n",
                "spark.sql(query_1).show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Sales by Brand per Month"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query_2 = \"\"\"\n",
                "SELECT \n",
                "    p.brand_nm,\n",
                "    d.year,\n",
                "    d.month,\n",
                "    SUM(f.dollar_volume) as total_volume\n",
                "FROM fact_sales f\n",
                "JOIN dim_product p ON f.product_key = p.product_key\n",
                "JOIN dim_date d ON f.date_key = d.date_key\n",
                "GROUP BY p.brand_nm, d.year, d.month\n",
                "ORDER BY p.brand_nm, d.year, d.month\n",
                "\"\"\"\n",
                "spark.sql(query_2).show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}